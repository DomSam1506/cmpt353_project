{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2f1782",
   "metadata": {},
   "source": [
    "# Statistical Testing on Video Game Ratings\n",
    "\n",
    "This notebook performs hypothesis testing to understand patterns in user ratings.  \n",
    "\n",
    "We compare user and critic ratings, examine the influence of maturity and platform, and identify statistically significant differences using non-parametric tests where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2638513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'avg_user_rating', 'user_ratings_count', 'reviews_count',\n",
       "       'added', 'avg_playtime', 'esrb_rating', 'release_year', 'release_month',\n",
       "       'release_quarter', 'critic_rating', 'rating_gap', 'genre_count',\n",
       "       'is_action', 'is_adventure', 'is_arcade', 'is_board_games', 'is_card',\n",
       "       'is_casual', 'is_educational', 'is_family', 'is_fighting', 'is_indie',\n",
       "       'is_massively_multiplayer', 'is_platformer', 'is_puzzle', 'is_rpg',\n",
       "       'is_racing', 'is_shooter', 'is_simulation', 'is_sports', 'is_strategy',\n",
       "       'platform_type', 'platform_count', 'store_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy import stats\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "games = pd.read_csv(\"..\\data\\games_data_cleaned.csv\")\n",
    "games.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803eabd",
   "metadata": {},
   "source": [
    "### Are User and Critic Ratings Statistically Different? (Supplementary, Not included in report)\n",
    "\n",
    "**Hypothesis:**  \n",
    "H₀: There is no difference between the average user rating and average critic rating.\n",
    "\n",
    "H₁: There is a significant difference between the two.\n",
    "\n",
    "**Test Used:** Paired t-test\n",
    "\n",
    "**Why:** Both ratings refer to the same games, so they are dependent samples. We use the paired t-test to compare the mean difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02ec653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(3.2629980300418615), np.float64(3.734782608695652))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games['avg_user_rating'].mean(), games['critic_rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a742ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "paired = games[['avg_user_rating', 'critic_rating', 'rating_gap']].dropna().copy()\n",
    "\n",
    "# Check normality\n",
    "stat, p = stats.shapiro(paired['rating_gap'])\n",
    "print(f\"p-value: {p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a55438",
   "metadata": {},
   "source": [
    "Data not normal but paired t test is robust to minor violations of normality if sample large: https://pythonfordatascienceorg.wordpress.com/paired-samples-t-test-python/#test-assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c34c248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test: p = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Run paired t-test\n",
    "t_stat, p_val = stats.ttest_rel(paired['avg_user_rating'], paired['critic_rating'])\n",
    "print(f\"Paired t-test: p = {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd65e89",
   "metadata": {},
   "source": [
    "### Do ESRB Maturity Ratings Affect User Ratings?\n",
    "\n",
    "**Hypothesis:**  \n",
    "H₀: The average user rating does not differ across ESRB maturity categories. (Teen, Mature and Everyone)  \n",
    "\n",
    "H₁: At least one ESRB category differs significantly in average user ratings.\n",
    "\n",
    "**Test Used:** Kruskal-Wallis + Dunn's Post-hoc\n",
    "\n",
    "**Why:** The normality assumption fails for all three groups. Kruskal-Wallis is a non-parametric alternative to ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2467e798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teen: p value =0.0000\n",
      "Mature: p value =0.0000\n",
      "Everyone: p value =0.0000\n"
     ]
    }
   ],
   "source": [
    "esrb = ['Teen', 'Mature','Everyone']\n",
    "\n",
    "for e in esrb:\n",
    "    e_rating = games[games['esrb_rating'] == e]['avg_user_rating']\n",
    "    p = stats.normaltest(e_rating).pvalue\n",
    "    print(f\"{e}: p value ={p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8df52575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's test p-value: 0.015083017164754815\n",
      "Kruskal-Wallis p-value: 2.279578976747048e-12\n"
     ]
    }
   ],
   "source": [
    "teen = games[games['esrb_rating'] == 'Teen']['avg_user_rating']\n",
    "mature = games[games['esrb_rating'] == 'Mature']['avg_user_rating']\n",
    "every = games[games['esrb_rating'] == 'Everyone']['avg_user_rating']\n",
    "\n",
    "\n",
    "print(\"Levene's test p-value:\",stats.levene(teen, mature, every).pvalue)\n",
    "\n",
    "print(\"Kruskal-Wallis p-value:\",stats.kruskal(teen,mature,every).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "673f9970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Everyone</th>\n",
       "      <th>Mature</th>\n",
       "      <th>Teen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Everyone</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.317894e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mature</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.470862e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teen</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.470862e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Everyone        Mature          Teen\n",
       "Everyone  1.000000  1.317894e-05  1.000000e+00\n",
       "Mature    0.000013  1.000000e+00  4.470862e-12\n",
       "Teen      1.000000  4.470862e-12  1.000000e+00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "\n",
    "maturity = games[['esrb_rating', 'avg_user_rating']].dropna().copy()\n",
    "maturity = maturity[maturity['esrb_rating'].isin(esrb)]\n",
    "\n",
    "posthoc = sp.posthoc_dunn(maturity, val_col = 'avg_user_rating', group_col='esrb_rating', p_adjust='bonferroni')\n",
    "posthoc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a121ab0",
   "metadata": {},
   "source": [
    "### Do Multi Platform(Console and PC) and PC only Games have different user ratings\n",
    "\n",
    "**Hypothesis:**  \n",
    "H₀: There is no difference in user ratings between multi platform and pc only  \n",
    "\n",
    "H₁: There is a difference between the platform ratings\n",
    "\n",
    "**Test Used:** Mann Whitney U Test \n",
    "\n",
    "**Why:** Normality assumption fails for both groups and no equal variance; thus,non-parametric testing is more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e431f6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "platform_type\n",
       "multi_platform    3768\n",
       "pc_only           3690\n",
       "console_only       594\n",
       "other               70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games['platform_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57c57b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi platform normality:  8.924437713928959e-35\n",
      "PC platform normality:  1.623991834224775e-107\n",
      "Levene's test p-value: 8.6533494793048e-78\n"
     ]
    }
   ],
   "source": [
    "# Group ratings by platform type\n",
    "multi = games[games['platform_type'] == 'multi_platform']['avg_user_rating']\n",
    "pc = games[games['platform_type'] == 'pc_only']['avg_user_rating']\n",
    "\n",
    "\n",
    "# Normality check per platform group\n",
    "print(\"Multi platform normality: \",stats.normaltest(multi).pvalue)\n",
    "print(\"PC platform normality: \", stats.normaltest(pc).pvalue)\n",
    "\n",
    "# Levene’s test for equal variances\n",
    "print(\"Levene's test p-value:\", stats.levene(multi, pc).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca9cd6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U p-value:  6.21920733118219e-181\n"
     ]
    }
   ],
   "source": [
    "print(\"Mann Whitney U p-value: \",stats.mannwhitneyu(multi, pc, alternative ='two-sided').pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
